{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luiz.tavares/.local/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: /nfs/home/luiz.tavares/.local/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104impl8GPUTrace13gpuTraceStateE\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "#PIL.PILLOW_VERSION = PIL.__version__\n",
    "\n",
    "from src.dataset import VDAODataset\n",
    "from src import RESULT_DIR\n",
    "from src.utils import MCC, DIS, conf_mat\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Silhouette test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "result_dict = {}\n",
    "pickle.dump(result_dict, open(os.path.join(RESULT_DIR,'silhouette.pkl'), 'wb'))\n",
    "\n",
    "for fold in range(1,10):\n",
    "    print(fold, end='\\r')\n",
    "    temp_dict = {}\n",
    "    dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                        alignment = 'elastic', transform = False)\n",
    "\n",
    "    dd = dataset.align_df\n",
    "    vid_list = dd.test_file.unique()\n",
    "\n",
    "    for vid in vid_list:\n",
    "        idxs = list(dd[dd.test_file==vid].index)\n",
    "        arr = np.array([dataset.__getitem__(ii)[2] for ii in idxs])\n",
    "        arr[arr == 0.5] = 127\n",
    "        arr[arr == 1] = 255\n",
    "        temp_dict[int(vid)] = arr.astype('uint8')\n",
    "        \n",
    "    res_dict = pickle.load(open(os.path.join(RESULT_DIR,\n",
    "                                             'silhouette.pkl'),'rb'))\n",
    "    res_dict[int(fold)] = temp_dict\n",
    "    pickle.dump(res_dict, open(os.path.join(RESULT_DIR,\n",
    "                                            'silhouette.pkl'), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating MCBS test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "base_dir =  '/nfs/proc/luiz.tavares/other_methods/MCBS/'\n",
    "res_dict = {}\n",
    "pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                           'MCBS_Both.pkl'), 'wb'))\n",
    "\n",
    "for fold in range(1,10):\n",
    "\n",
    "    print(fold, end='\\r')\n",
    "    img_dir = os.path.join(base_dir,'fold{0:02d}/Both'.format(fold))\n",
    "\n",
    "    temp_dict = {}\n",
    "    dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                         alignment = 'elastic', transform = False)\n",
    "\n",
    "    dd = dataset.align_df\n",
    "    vid_list = dd.test_file.unique()\n",
    "\n",
    "    for vid in vid_list:\n",
    "        idxs = list(dd[dd.test_file==vid].index)\n",
    "        arr = [cv2.imread(os.path.join(img_dir, '{0}.png'.format(ii)))[:,:,0] \n",
    "               for ii in idxs]\n",
    "        temp_dict[int(vid)] = np.array(arr).astype('uint8')\n",
    "        \n",
    "    # Saving progress\n",
    "    res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'MCBS_Both.pkl'),'rb'))\n",
    "    res_dict[int(fold)] = temp_dict\n",
    "    pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'MCBS_Both.pkl'), 'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "base_dir =  '/nfs/proc/luiz.tavares/other_methods/MCBS/'\n",
    "res_dict = {}\n",
    "pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                           'MCBS_NVD.pkl'), 'wb'))\n",
    "\n",
    "for fold in range(1,10):\n",
    "\n",
    "    print(fold, end='\\r')\n",
    "    img_dir = os.path.join(base_dir,'fold{0:02d}/NVD'.format(fold))\n",
    "\n",
    "    temp_dict = {}\n",
    "    dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                        alignment = 'elastic', transform = False)\n",
    "\n",
    "    dd = dataset.align_df\n",
    "    vid_list = dd.test_file.unique()\n",
    "\n",
    "    for vid in vid_list:\n",
    "        idxs = list(dd[dd.test_file==vid].index)\n",
    "        arr = [cv2.imread(os.path.join(img_dir, '{0}.png'.format(ii)))[:,:,0] \n",
    "               for ii in idxs]\n",
    "        temp_dict[int(vid)] = np.array(arr).astype('uint8')\n",
    "        \n",
    "    # Saving progress\n",
    "    res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'MCBS_NVD.pkl'),'rb'))\n",
    "    res_dict[int(fold)] = temp_dict\n",
    "    pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'MCBS_NVD.pkl'), 'wb'))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "base_dir =  '/nfs/proc/luiz.tavares/other_methods/MCBS/'\n",
    "res_dict = {}\n",
    "pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                           'MCBS_RRF.pkl'), 'wb'))\n",
    "\n",
    "for fold in range(1,10):\n",
    "\n",
    "    print(fold, end='\\r')\n",
    "    img_dir = os.path.join(base_dir,'fold{0:02d}/RRF'.format(fold))\n",
    "\n",
    "    temp_dict = {}\n",
    "    dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                        alignment = 'elastic', transform = False)\n",
    "\n",
    "    dd = dataset.align_df\n",
    "    vid_list = dd.test_file.unique()\n",
    "\n",
    "    for vid in vid_list:\n",
    "        idxs = list(dd[dd.test_file==vid].index)\n",
    "        arr = [cv2.imread(os.path.join(img_dir, '{0}.png'.format(ii)))[:,:,0] \n",
    "               for ii in idxs]\n",
    "        temp_dict[int(vid)] = np.array(arr).astype('uint8')\n",
    "        \n",
    "    # Saving progress\n",
    "    res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'MCBS_RRF.pkl'),'rb'))\n",
    "    res_dict[int(fold)] = temp_dict\n",
    "    pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'MCBS_RRF.pkl'), 'wb'))    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating mcDTSR test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "base_dir =  '/nfs/proc/luiz.tavares/other_methods/mcDTSR/'\n",
    "modes = ['', 'e']\n",
    "for mm in modes:\n",
    "    res_dict = {}\n",
    "    pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'mcDTSR{0}.pkl'.format(mm)), 'wb'))\n",
    "    for fold in range(1,10):\n",
    "\n",
    "        print(fold, end='\\r')\n",
    "        temp_dict = {}\n",
    "        dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                            alignment = 'elastic', transform = False)\n",
    "\n",
    "        dd = dataset.align_df\n",
    "        vid_list = dd.test_file.unique()\n",
    "\n",
    "        for vid in vid_list:\n",
    "            img_dir = os.path.join(base_dir,'{0:02d}'.format(int(vid)))\n",
    "            idxs = list(range(1,201))\n",
    "            arr = [cv2.imread(os.path.join(img_dir, '{1}{0}.png'.format(ii, mm)))[:,:,0] \n",
    "                for ii in idxs]\n",
    "            arr += arr[199]\n",
    "            temp_dict[int(vid)] = np.array(arr).astype('uint8')\n",
    "            \n",
    "        # Saving progress\n",
    "        res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                                'mcDTSR{0}.pkl'.format(mm)),'rb'))\n",
    "        res_dict[int(fold)] = temp_dict\n",
    "        pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                                'mcDTSR{0}.pkl'.format(mm)), 'wb'))   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating DAOMC test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\r"
     ]
    }
   ],
   "source": [
    "base_dir =  '/nfs/proc/luiz.tavares/other_methods/DAOMC/'\n",
    "modes = ['']\n",
    "for mm in modes:\n",
    "    res_dict = {}\n",
    "#    pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "#                                            'DAOMC.pkl'), 'wb'))\n",
    "    for fold in range(1,10):\n",
    "\n",
    "        print(fold, end='\\r')\n",
    "        temp_dict = {}\n",
    "        dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                              alignment = 'elastic', transform = False)\n",
    "\n",
    "        dd = dataset.align_df\n",
    "        vid_list = dd.test_file.unique()\n",
    "\n",
    "        for vid in vid_list:\n",
    "            vv = int(vid)\n",
    "            cap = cv2.VideoCapture(os.path.join(base_dir,\n",
    "                                                '{0:02d}.mp4'.format(vv)))\n",
    "            idxs = list(range(0,201))\n",
    "            arr = [cap.read()[1] for ii in idxs]\n",
    "            temp_dict[vv] = np.array(arr).astype('uint8')\n",
    "            \n",
    "        # Saving progress\n",
    "        res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                                'DAOMC.pkl'),'rb'))\n",
    "        res_dict[int(fold)] = temp_dict\n",
    "        pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                                'DAOMC.pkl'), 'wb'))   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating ADMULT test file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\r"
     ]
    }
   ],
   "source": [
    "base_dir =  '/nfs/proc/luiz.tavares/other_methods/ADMULT/'\n",
    "modes = ['']\n",
    "for mm in modes:\n",
    "    res_dict = {}\n",
    "    pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                           'ADMULT.pkl'), 'wb'))\n",
    "    for fold in range(1,10):\n",
    "\n",
    "        print(fold, end='\\r')\n",
    "        temp_dict = {}\n",
    "        dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                              alignment = 'elastic', transform = False)\n",
    "\n",
    "        dd = dataset.align_df\n",
    "        vid_list = dd.test_file.unique()\n",
    "\n",
    "        for vid in vid_list:\n",
    "            vv = int(vid)\n",
    "            cap = cv2.VideoCapture(os.path.join(base_dir,\n",
    "                                                '{0:02d}.mp4'.format(vv)))\n",
    "            idxs = list(range(0,201))\n",
    "            arr = [cap.read()[1] for ii in idxs]\n",
    "            temp_dict[vv] = np.array(arr).astype('uint8')[:,:,:,0]\n",
    "            \n",
    "        # Saving progress\n",
    "        res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                                'ADMULT.pkl'),'rb'))\n",
    "        res_dict[int(fold)] = temp_dict\n",
    "        pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                                'ADMULT.pkl'), 'wb'))   \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESULTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sil_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                        'silhouette.pkl'),'rb'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample = {'mcDTSR':1,'mcDTSRe':1, 'MCBS_Both':1, 'MCBS_RRF':1, 'DAOMC':1,\n",
    "             'ADMULT':1}\n",
    "results = {'mcDTSR':{}, 'mcDTSRe':{}, 'MCBS_Both':{}, 'MCBS_RRF':{},\n",
    "           'DAOMC':{}, 'ADMULT':{}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'mcDTSR'\n",
    "res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                        '{0}.pkl'.format(method)),'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.281689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.259314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.180086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.034025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-0.003475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         dis\n",
       "1   0.281689\n",
       "2   0.000000\n",
       "3   0.000000\n",
       "4   0.052773\n",
       "5   0.259314\n",
       "6   0.000000\n",
       "7   0.000000\n",
       "8   0.000000\n",
       "9   0.000000\n",
       "10  0.000000\n",
       "11  0.000000\n",
       "12  0.000000\n",
       "13  0.000000\n",
       "14  0.000000\n",
       "15  0.000000\n",
       "16  0.000000\n",
       "17  0.000000\n",
       "18  0.000000\n",
       "19  0.000000\n",
       "20  0.000000\n",
       "21  0.000000\n",
       "22  0.000000\n",
       "23  0.000000\n",
       "24  0.000000\n",
       "25  0.000000\n",
       "26  0.000000\n",
       "27  0.000000\n",
       "28  0.000000\n",
       "29  0.000000\n",
       "30  0.000000\n",
       "31  0.000000\n",
       "32  0.000000\n",
       "33  0.180086\n",
       "34  0.000000\n",
       "35  0.000000\n",
       "36  0.034025\n",
       "37  0.000000\n",
       "38  0.000000\n",
       "39  0.000000\n",
       "40  0.000000\n",
       "41  0.000000\n",
       "42  0.000000\n",
       "43  0.000000\n",
       "44  0.000000\n",
       "45  0.000000\n",
       "46  0.000000\n",
       "47  0.000000\n",
       "48  0.000000\n",
       "49  0.000000\n",
       "50  0.000000\n",
       "51  0.000000\n",
       "52 -0.003475\n",
       "53  0.000000\n",
       "54  0.000000\n",
       "55  0.000000\n",
       "56  0.000000\n",
       "57  0.000000\n",
       "58  0.000000\n",
       "59  0.000000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn_sum, fp_sum, fn_sum, tp_sum = 0, 0, 0, 0\n",
    "for fold in range(1,10):\n",
    "    vids = list(sil_dict[fold].keys())\n",
    "    for vid in vids:\n",
    "        frame_out = res_dict[fold][vid][0]\n",
    "        frame_sil = sil_dict[fold][vid][0]\n",
    "        out_y, out_x = frame_out.shape[0], frame_out.shape[1]\n",
    "        delta_x = (frame_sil.shape[1] - out_x)//2\n",
    "        delta_y = (frame_sil.shape[0] - out_y)//2\n",
    "\n",
    "        output_arr     = res_dict[fold][vid]\n",
    "        silhouette_arr = sil_dict[fold][vid][:,delta_y:delta_y+out_y,\n",
    "                                             delta_x:delta_x+out_x:subsample[method]]\n",
    "        if res_dict[fold][vid].shape[0] == 200:\n",
    "            output_arr = np.concatenate((output_arr,output_arr[-1,:][None,:]),axis=0)\n",
    "\n",
    "        silhouette = silhouette_arr.flatten()\n",
    "        output = output_arr.flatten()\n",
    "\n",
    "        output = output[silhouette != 127].flatten()//128\n",
    "        silhouette = silhouette[silhouette != 127].flatten()//128\n",
    "\n",
    "        tn, fp, fn, tp = conf_mat(silhouette, output).ravel()\n",
    "        tn_sum += tn\n",
    "        fp_sum += fp\n",
    "        fn_sum += fn\n",
    "        tp_sum += tp\n",
    "\n",
    "        metric = MCC(tn, fp, fn, tp)\n",
    "        results[method][vid] = metric\n",
    "res_df = pd.DataFrame.from_dict(results[method],\n",
    "                 orient='index', columns=['dis']).sort_index(ascending=True)\n",
    "res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03688756000140028"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCC(tn_sum, fp_sum, fn_sum, tp_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 254, 255], dtype=uint8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(res_dict[fold][vid][0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ADMULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14144/1034829479.py:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  temp_dict[int(vid)] = np.array(arr).astype('uint8')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_14144/1034829479.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m201\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mtemp_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'uint8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Saving progress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "base_dir =  '/home/luiz.tavares/Softwares/vad/video/admult/'\n",
    "\n",
    "pickle.dump({}, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                 'ADMULT.pkl'), 'wb'))  \n",
    "for fold in range(1,10):\n",
    "\n",
    "    print(fold, end='\\r')\n",
    "    temp_dict = {}\n",
    "    dataset = VDAODataset(fold = fold, split = 0, type = 'test',\n",
    "                         alignment = 'elastic', transform = False)\n",
    "\n",
    "    dd = dataset.align_df\n",
    "    vid_list = dd.test_file.unique()\n",
    "\n",
    "    for vid in vid_list:\n",
    "        vid_dir = os.path.join(base_dir,'{0:02d}.avi'.format(int(vid)))\n",
    "        cap = cv2.VideoCapture(vid_dir)\n",
    "        arr = [cap.read()[1] for i in range(201)]\n",
    "\n",
    "        temp_dict[int(vid)] = np.array(arr).astype('uint8')\n",
    "        \n",
    "    # Saving progress\n",
    "    res_dict = pickle.load(open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'ADMULT.pkl'),'rb'))\n",
    "    res_dict[int(fold)] = temp_dict\n",
    "    pickle.dump(res_dict, open(os.path.join(RESULT_DIR, 'test_results',\n",
    "                                            'ADMULT.pkl'), 'wb'))  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(vid_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir =  '/nfs/proc/luiz.tavares/other_methods/mcDTSR/'\n",
    "\n",
    "for folder in range(1,59):\n",
    "    \n",
    "    dir = os.path.join(base_dir, '{0:02d}'.format(folder))\n",
    "    \n",
    "    for i in range(1,201):\n",
    "        img = os.path.join(dir, '{0}.png'.format(i))\n",
    "        if not os.path.isfile(img):\n",
    "            print('Video {0:02d} - Frame {1:03d}'.format(folder, i))\n",
    "            \n",
    "    for i in range(1,201):\n",
    "        img = os.path.join(dir, 'e{0}.png'.format(i))\n",
    "        if not os.path.isfile(img):\n",
    "            print('Video {0:02d} - Frame e{1:03d}'.format(folder, i))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixel_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3fe4b717e41534989dd514def504f4e45872ef3d1cf72d7948bd023446991b72"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
